{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19C2vKEY_y3sZ5cX8r3QkE00a55Rg5lOe",
      "authorship_tag": "ABX9TyMTmDlwTYUN9kI1hUUDoBUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeseeboy/beverage-bottle-detection-model/blob/main/Beverage_bottle_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx8Fbhb8xcDB",
        "outputId": "b633c25a-e599-4285-f7eb-908c56f37f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.145-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.64-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.145-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.1.64-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, nvidia-cusparse-cu12, nvidia-cudnn-cu12, supervision, nvidia-cusolver-cu12, roboflow, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed filetype-1.2.0 idna-3.7 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.64 supervision-0.25.1 ultralytics-8.3.145 ultralytics-thop-2.0.14\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "✅ Setup completed!\n",
            "CUDA Available: True\n",
            "Device: Tesla T4\n",
            "📁 Project structure created at: /content/drive/MyDrive/BeverageDetection\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive and Install Dependencies\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install ultralytics roboflow supervision\n",
        "\n",
        "# Import required libraries\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"✅ Setup completed!\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "# Define project paths\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/BeverageDetection\"\n",
        "DATASET_PATH = f\"{PROJECT_ROOT}/dataset\"\n",
        "MODELS_PATH = f\"{PROJECT_ROOT}/models\"\n",
        "CHECKPOINTS_PATH = f\"{MODELS_PATH}/checkpoints\"\n",
        "BEST_MODELS_PATH = f\"{MODELS_PATH}/best_models\"\n",
        "RUNS_PATH = f\"{PROJECT_ROOT}/runs\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(PROJECT_ROOT, exist_ok=True)\n",
        "os.makedirs(DATASET_PATH, exist_ok=True)\n",
        "os.makedirs(CHECKPOINTS_PATH, exist_ok=True)\n",
        "os.makedirs(BEST_MODELS_PATH, exist_ok=True)\n",
        "os.makedirs(RUNS_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"📁 Project structure created at: {PROJECT_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Extract and Prepare Dataset\n",
        "def extract_dataset(zip_path, extract_to):\n",
        "    \"\"\"Extracts the dataset from a zip file to the specified directory.\"\"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Dataset extracted to: {extract_to}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting dataset: {e}\")\n",
        "        return False\n",
        "\n",
        "def prepare_data_yaml(dataset_path):\n",
        "    \"\"\"Modifies data.yaml to include absolute paths for train, val, and test directories.\"\"\"\n",
        "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
        "\n",
        "    if os.path.exists(yaml_path):\n",
        "        with open(yaml_path, 'r') as file:\n",
        "            data = yaml.safe_load(file)\n",
        "\n",
        "        # Set absolute paths for training, validation, and test data\n",
        "        data['train'] = os.path.join(dataset_path, 'train/images')\n",
        "        data['val'] = os.path.join(dataset_path, 'valid/images')\n",
        "        data['test'] = os.path.join(dataset_path, 'test/images')\n",
        "\n",
        "        with open(yaml_path, 'w') as file:\n",
        "            yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "        print(\"Updated data.yaml with correct paths\")\n",
        "        print(\"Dataset details:\")\n",
        "        print(f\"  - Classes: {data['nc']}\")\n",
        "        print(f\"  - Train images: {data['train']}\")\n",
        "        print(f\"  - Val images: {data['val']}\")\n",
        "        print(f\"  - Test images: {data['test']}\")\n",
        "\n",
        "        return yaml_path, data\n",
        "    else:\n",
        "        print(f\"data.yaml not found at {yaml_path}\")\n",
        "        return None, None\n",
        "\n",
        "# Extract the dataset zip file\n",
        "ZIP_FILE = \"/content/drive/MyDrive/BeverageDetection/dataset/data.zip\"\n",
        "\n",
        "if os.path.exists(ZIP_FILE):\n",
        "    extract_success = extract_dataset(ZIP_FILE, DATASET_PATH)\n",
        "    if extract_success:\n",
        "        yaml_path, dataset_info = prepare_data_yaml(DATASET_PATH)\n",
        "else:\n",
        "    print(f\"Dataset zip file not found at: {ZIP_FILE}\")\n",
        "    print(\"Please upload the dataset zip file and update the ZIP_FILE variable accordingly.\")\n",
        "\n",
        "# Verify the dataset directory structure\n",
        "def verify_dataset_structure(dataset_path):\n",
        "    \"\"\"Checks for the presence of required folders and counts contained files.\"\"\"\n",
        "    required_folders = ['train/images', 'train/labels', 'valid/images', 'valid/labels']\n",
        "\n",
        "    for folder in required_folders:\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        if os.path.exists(folder_path):\n",
        "            count = len(os.listdir(folder_path))\n",
        "            print(f\"{folder}: {count} files\")\n",
        "        else:\n",
        "            print(f\"Missing folder: {folder}\")\n",
        "\n",
        "print(\"\\nVerifying dataset structure:\")\n",
        "verify_dataset_structure(DATASET_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3gImoQvyCGp",
        "outputId": "6af6154e-2d05-41f9-96aa-a9362220464f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted to: /content/drive/MyDrive/BeverageDetection/dataset\n",
            "✅ Updated data.yaml with correct paths\n",
            "📊 Dataset info:\n",
            "   - Classes: 73\n",
            "   - Train images: /content/drive/MyDrive/BeverageDetection/dataset/train/images\n",
            "   - Val images: /content/drive/MyDrive/BeverageDetection/dataset/valid/images\n",
            "   - Test images: /content/drive/MyDrive/BeverageDetection/dataset/test/images\n",
            "\n",
            "📋 Dataset Structure Verification:\n",
            "✅ train/images: 3828 files\n",
            "✅ train/labels: 3828 files\n",
            "✅ valid/images: 1094 files\n",
            "✅ valid/labels: 1094 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "\n",
        "class BeverageDetectionTrainer:\n",
        "    def __init__(self, dataset_yaml_path, project_root):\n",
        "        self.dataset_yaml_path = dataset_yaml_path\n",
        "        self.project_root = project_root\n",
        "        self.checkpoints_path = f\"{project_root}/models/checkpoints\"\n",
        "        self.best_models_path = f\"{project_root}/models/best_models\"\n",
        "        self.training_log_path = f\"{project_root}/training_log.json\"\n",
        "\n",
        "        # Create directories if they don't exist\n",
        "        os.makedirs(self.checkpoints_path, exist_ok=True)\n",
        "        os.makedirs(self.best_models_path, exist_ok=True)\n",
        "\n",
        "    def save_training_state(self, epoch, model_path, metrics):\n",
        "        \"\"\"Save training state for resuming\"\"\"\n",
        "        state = {\n",
        "            'epoch': epoch,\n",
        "            'model_path': model_path,\n",
        "            'metrics': metrics,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'dataset_path': self.dataset_yaml_path\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(self.training_log_path, 'w') as f:\n",
        "                json.dump(state, f, indent=2)\n",
        "            print(f\"💾 Training state saved at epoch {epoch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not save training state: {e}\")\n",
        "\n",
        "    def load_training_state(self):\n",
        "        \"\"\"Load previous training state\"\"\"\n",
        "        if os.path.exists(self.training_log_path):\n",
        "            try:\n",
        "                with open(self.training_log_path, 'r') as f:\n",
        "                    state = json.load(f)\n",
        "                print(f\"📂 Found previous training state from epoch {state['epoch']}\")\n",
        "                return state\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Could not load training state: {e}\")\n",
        "        return None\n",
        "\n",
        "    def train_model(self, epochs=50, img_size=640, batch_size=16, resume=True):\n",
        "        \"\"\"Train YOLO model with checkpointing\"\"\"\n",
        "\n",
        "        # Validate dataset path\n",
        "        if not os.path.exists(self.dataset_yaml_path):\n",
        "            raise FileNotFoundError(f\"Dataset YAML not found: {self.dataset_yaml_path}\")\n",
        "\n",
        "        # Check for previous training state\n",
        "        previous_state = None\n",
        "        if resume:\n",
        "            previous_state = self.load_training_state()\n",
        "\n",
        "        # Initialize model\n",
        "        if previous_state and os.path.exists(previous_state['model_path']):\n",
        "            print(f\"🔄 Resuming training from {previous_state['model_path']}\")\n",
        "            model = YOLO(previous_state['model_path'])\n",
        "            start_epoch = previous_state['epoch']\n",
        "        else:\n",
        "            print(\"🚀 Starting fresh training\")\n",
        "            model = YOLO('yolov8n.pt')  # Start with pre-trained weights\n",
        "            start_epoch = 0\n",
        "\n",
        "        # Detect device\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print(f\"🖥️  Using device: {device}\")\n",
        "\n",
        "        # Training parameters\n",
        "        train_params = {\n",
        "            'data': self.dataset_yaml_path,\n",
        "            'epochs': epochs,\n",
        "            'imgsz': img_size,\n",
        "            'batch': batch_size,\n",
        "            'device': device,\n",
        "            'workers': 2 if device == 'cpu' else 4,\n",
        "            'project': self.project_root,\n",
        "            'name': 'beverage_detection_training',\n",
        "            'save_period': 10,  # Save checkpoint every 10 epochs\n",
        "            'patience': 50,     # Early stopping patience\n",
        "            'save': True,\n",
        "            'val': True,\n",
        "            'plots': True,\n",
        "            'verbose': True,\n",
        "            'cache': True,      # Cache images for faster training\n",
        "            'optimizer': 'SGD', # SGD or Adam\n",
        "            'lr0': 0.01,        # Initial learning rate\n",
        "            'momentum': 0.937,  # SGD momentum\n",
        "            'weight_decay': 0.0005,\n",
        "            'warmup_epochs': 3.0,\n",
        "            'warmup_momentum': 0.8,\n",
        "            'warmup_bias_lr': 0.1\n",
        "        }\n",
        "\n",
        "        print(f\"🎯 Training Configuration:\")\n",
        "        for key, value in train_params.items():\n",
        "            print(f\"   {key}: {value}\")\n",
        "\n",
        "        try:\n",
        "            # Start training\n",
        "            print(f\"\\n⏰ Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            results = model.train(**train_params)\n",
        "\n",
        "            # Get the best model path\n",
        "            best_model_source = results.save_dir / 'weights' / 'best.pt'\n",
        "            best_model_path = f\"{self.best_models_path}/best_beverage_model.pt\"\n",
        "\n",
        "            # Copy the best model\n",
        "            if os.path.exists(best_model_source):\n",
        "                shutil.copy(str(best_model_source), best_model_path)\n",
        "                print(f\"📁 Best model saved to: {best_model_path}\")\n",
        "\n",
        "            # Extract final metrics safely\n",
        "            final_metrics = {}\n",
        "            try:\n",
        "                if hasattr(results, 'box'):\n",
        "                    final_metrics = {\n",
        "                        'map50': float(results.box.map50) if hasattr(results.box, 'map50') else 0.0,\n",
        "                        'map': float(results.box.map) if hasattr(results.box, 'map') else 0.0,\n",
        "                        'precision': float(results.box.mp) if hasattr(results.box, 'mp') else 0.0,\n",
        "                        'recall': float(results.box.mr) if hasattr(results.box, 'mr') else 0.0\n",
        "                    }\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Could not extract metrics: {e}\")\n",
        "                final_metrics = {'error': str(e)}\n",
        "\n",
        "            # Save final training state\n",
        "            self.save_training_state(epochs, best_model_path, final_metrics)\n",
        "\n",
        "            print(f\"\\n🎉 Training completed successfully!\")\n",
        "            print(f\"⏰ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "            if final_metrics and 'error' not in final_metrics:\n",
        "                print(f\"📈 Final Metrics:\")\n",
        "                print(f\"   mAP@0.5: {final_metrics.get('map50', 'N/A'):.4f}\")\n",
        "                print(f\"   mAP@0.5:0.95: {final_metrics.get('map', 'N/A'):.4f}\")\n",
        "                print(f\"   Precision: {final_metrics.get('precision', 'N/A'):.4f}\")\n",
        "                print(f\"   Recall: {final_metrics.get('recall', 'N/A'):.4f}\")\n",
        "\n",
        "            return model, results\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(f\"\\n⏸️  Training interrupted by user at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "            self._save_interrupted_state(model, start_epoch)\n",
        "            raise\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Training error: {e}\")\n",
        "            self._save_interrupted_state(model, start_epoch)\n",
        "            raise e\n",
        "\n",
        "    def _save_interrupted_state(self, model, start_epoch):\n",
        "        \"\"\"Save state when training is interrupted\"\"\"\n",
        "        try:\n",
        "            current_epoch = getattr(model.trainer, 'epoch', start_epoch) if hasattr(model, 'trainer') else start_epoch\n",
        "            current_model_path = f\"{self.checkpoints_path}/interrupted_epoch_{current_epoch}.pt\"\n",
        "\n",
        "            # Try to save the current model state\n",
        "            if hasattr(model, 'trainer') and hasattr(model.trainer, 'last'):\n",
        "                if os.path.exists(model.trainer.last):\n",
        "                    shutil.copy(model.trainer.last, current_model_path)\n",
        "                    self.save_training_state(current_epoch, current_model_path, {})\n",
        "                    print(f\"💾 Progress saved to: {current_model_path}\")\n",
        "                    print(f\"🔄 Resume by running the training again\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not save interrupted state: {e}\")\n",
        "\n",
        "    def validate_model(self, model_path=None):\n",
        "        \"\"\"Run validation on trained model\"\"\"\n",
        "        if model_path is None:\n",
        "            model_path = f\"{self.best_models_path}/best_beverage_model.pt\"\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"❌ Model not found: {model_path}\")\n",
        "            return None\n",
        "\n",
        "        print(f\"🔍 Running validation on: {model_path}\")\n",
        "        model = YOLO(model_path)\n",
        "        results = model.val(data=self.dataset_yaml_path)\n",
        "\n",
        "        print(f\"📊 Validation Results:\")\n",
        "        print(f\"   mAP@0.5: {results.box.map50:.4f}\")\n",
        "        print(f\"   mAP@0.5:0.95: {results.box.map:.4f}\")\n",
        "        print(f\"   Precision: {results.box.mp:.4f}\")\n",
        "        print(f\"   Recall: {results.box.mr:.4f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# Main training execution\n",
        "def run_training(dataset_yaml_path, project_root, epochs=50, img_size=640, batch_size=16):\n",
        "    \"\"\"Main function to run the complete training pipeline\"\"\"\n",
        "\n",
        "    print(\"🚀 YOLO Beverage Detection Training Pipeline\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = BeverageDetectionTrainer(dataset_yaml_path, project_root)\n",
        "\n",
        "    # Display configuration\n",
        "    print(f\"⚙️  Training Configuration:\")\n",
        "    print(f\"   Dataset: {dataset_yaml_path}\")\n",
        "    print(f\"   Project Root: {project_root}\")\n",
        "    print(f\"   Epochs: {epochs}\")\n",
        "    print(f\"   Image Size: {img_size}\")\n",
        "    print(f\"   Batch Size: {batch_size}\")\n",
        "    print(f\"   GPU Available: {torch.cuda.is_available()}\")\n",
        "    print(f\"   CUDA Version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n",
        "\n",
        "    try:\n",
        "        # Start training\n",
        "        model, results = trainer.train_model(\n",
        "            epochs=epochs,\n",
        "            img_size=img_size,\n",
        "            batch_size=batch_size,\n",
        "            resume=True\n",
        "        )\n",
        "\n",
        "        # Display training plots if available\n",
        "        plots_dir = f\"{project_root}/beverage_detection_training\"\n",
        "        if os.path.exists(plots_dir):\n",
        "            print(f\"\\n📊 Training plots saved in: {plots_dir}\")\n",
        "\n",
        "            # Try to display results plot\n",
        "            results_plot = f\"{plots_dir}/results.png\"\n",
        "            if os.path.exists(results_plot):\n",
        "                try:\n",
        "                    display(Image(results_plot))\n",
        "                except:\n",
        "                    print(f\"📈 Results plot available at: {results_plot}\")\n",
        "\n",
        "        # Run final validation\n",
        "        print(f\"\\n🔍 Running final validation...\")\n",
        "        trainer.validate_model()\n",
        "\n",
        "        return trainer, model, results\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n⏸️  Training interrupted by user\")\n",
        "        print(\"💾 Progress has been saved. Run again to resume.\")\n",
        "        return trainer, None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Training failed: {e}\")\n",
        "        print(\"💾 Progress has been saved. Check the error and run again to resume.\")\n",
        "        raise e\n",
        "\n",
        "# Direct execution section - combines both your original codes\n",
        "# This replaces both Step 3 and Step 4 from your original code\n",
        "\n",
        "# Configuration - Updated for your directory structure\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/BeverageDetection\"\n",
        "yaml_path = \"/content/drive/MyDrive/BeverageDetection/dataset/data.yaml\"  # This should be created from your unzipped data\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 50\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 16  # Reduce to 8 or 4 if you get GPU memory errors\n",
        "\n",
        "# Check if required variables exist (from your original code logic)\n",
        "if 'yaml_path' in locals() and yaml_path and yaml_path != \"path_to_your_dataset.yaml\":\n",
        "    # Initialize trainer (from your Step 3)\n",
        "    trainer = BeverageDetectionTrainer(yaml_path, PROJECT_ROOT)\n",
        "    print(\"✅ Trainer initialized and ready!\")\n",
        "\n",
        "    # Start training (from your Step 4)\n",
        "    print(\"\\n🚀 Starting YOLO Training...\")\n",
        "    print(f\"⚙️  Configuration:\")\n",
        "    print(f\"   Epochs: {EPOCHS}\")\n",
        "    print(f\"   Image Size: {IMG_SIZE}\")\n",
        "    print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "    print(f\"   GPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "    try:\n",
        "        # Start training (this will resume automatically if interrupted)\n",
        "        model, results = trainer.train_model(\n",
        "            epochs=EPOCHS,\n",
        "            img_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            resume=True  # Set to False if you want to start fresh\n",
        "        )\n",
        "\n",
        "        print(\"🎉 Training completed successfully!\")\n",
        "\n",
        "        # Display training plots if available\n",
        "        plots_dir = f\"{PROJECT_ROOT}/beverage_detection_training\"\n",
        "        if os.path.exists(plots_dir):\n",
        "            print(f\"📊 Training plots saved in: {plots_dir}\")\n",
        "\n",
        "            # Show results plot if available\n",
        "            results_plot = f\"{plots_dir}/results.png\"\n",
        "            if os.path.exists(results_plot):\n",
        "                try:\n",
        "                    display(Image(results_plot))\n",
        "                except:\n",
        "                    print(f\"📈 Results plot available at: {results_plot}\")\n",
        "\n",
        "        # Quick validation check if training completed\n",
        "        if 'model' in locals():\n",
        "            print(\"\\n🔍 Quick Model Validation:\")\n",
        "            val_results = model.val()\n",
        "            print(f\"   Validation mAP@0.5: {val_results.box.map50:.4f}\")\n",
        "            print(f\"   Validation mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"⏸️  Training interrupted by user\")\n",
        "        print(\"💾 Progress has been saved. Run this cell again to resume.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Training error: {e}\")\n",
        "        print(\"💾 Progress has been saved. Check the error and run again to resume.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Please update PROJECT_ROOT and yaml_path variables at the top of this code\")\n",
        "    print(\"📝 Set your actual paths and run again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL_LqZmqyqQF",
        "outputId": "f6923243-2d86-4a9b-92c8-5b75c6fa3a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Trainer initialized and ready!\n",
            "\n",
            "🚀 Starting YOLO Training...\n",
            "⚙️  Configuration:\n",
            "   Epochs: 50\n",
            "   Image Size: 640\n",
            "   Batch Size: 16\n",
            "   GPU Available: True\n",
            "🚀 Starting fresh training\n",
            "🖥️  Using device: cuda\n",
            "🎯 Training Configuration:\n",
            "   data: /content/drive/MyDrive/BeverageDetection/dataset/data.yaml\n",
            "   epochs: 50\n",
            "   imgsz: 640\n",
            "   batch: 16\n",
            "   device: cuda\n",
            "   workers: 4\n",
            "   project: /content/drive/MyDrive/BeverageDetection\n",
            "   name: beverage_detection_training\n",
            "   save_period: 10\n",
            "   patience: 50\n",
            "   save: True\n",
            "   val: True\n",
            "   plots: True\n",
            "   verbose: True\n",
            "   cache: True\n",
            "   optimizer: SGD\n",
            "   lr0: 0.01\n",
            "   momentum: 0.937\n",
            "   weight_decay: 0.0005\n",
            "   warmup_epochs: 3.0\n",
            "   warmup_momentum: 0.8\n",
            "   warmup_bias_lr: 0.1\n",
            "\n",
            "⏰ Training started at: 2025-05-27 17:36:46\n",
            "Ultralytics 8.3.145 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/BeverageDetection/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=beverage_detection_training2, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/BeverageDetection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/BeverageDetection/beverage_detection_training2, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=73\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    837205  ultralytics.nn.modules.head.Detect           [73, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,096,741 parameters, 3,096,725 gradients, 8.6 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 63.9±78.3 MB/s, size: 173.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/BeverageDetection/dataset/train/labels... 3828 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3828/3828 [01:15<00:00, 50.98it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/1673_jpg.rf.4abcb7fbf3de5a342c7f00c19da35270.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/2661_jpg.rf.010b0d5e25cbf7c09a8b66ee0a767510.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/2877_jpg.rf.b19cb3e8e461f93d0401e96986e1f082.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/2969_jpg.rf.be9e3ad7d50e244cb6e6e294e5b72c09.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3029_jpg.rf.1356660ffb1fb0b5df9184f52cd67362.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3037_jpg.rf.ef7fc1a7621a813dddf1a21e0d8dba16.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3090_jpg.rf.84f7e6b279b64b58ae9b696c55d6f7b8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3180_jpg.rf.a31d3965cf8da3f8f9664fea0d6643d3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3287_jpg.rf.166499cc96670fbecc66b19b3444d964.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3299_jpg.rf.1281af91640d303ee9e656e7d76d96d8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3641_jpg.rf.50aef01c704fb4e00d6aad1bbdf8a080.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3790_jpg.rf.5bd0ee0bfa463c7138cd1bfc9ffeaf49.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/3904_jpg.rf.5644626b4cb682fd30e494f794ddccde.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/4004_jpg.rf.ef577f175fb93738fcbaf270c37fb28e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/4244_jpg.rf.199e4ace8570ea881a7483e4e4998470.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/4306_jpg.rf.4a62f20cc47a8c4181e9b064d222e6b4.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/4366_jpg.rf.33155b39d36e07a1ed2ae1ba8de25641.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/train/images/4584_jpg.rf.7edc5aacce417fdbb9c064e5e803510f.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/BeverageDetection/dataset/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 178, len(boxes) = 57314. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.0GB RAM): 100%|██████████| 3828/3828 [01:22<00:00, 46.37it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.0±1.0 ms, read: 17.7±18.6 MB/s, size: 156.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/BeverageDetection/dataset/valid/labels... 1094 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1094/1094 [00:14<00:00, 73.73it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/valid/images/2815_jpg.rf.263b9fd7ba997f6278fbc88329ae4bce.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/valid/images/2865_jpg.rf.3020ef0dda8fb2e35f6ac8c4edfd3164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/valid/images/4021_jpg.rf.3516dd531ebfffd96b025e25fd67e363.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/BeverageDetection/dataset/valid/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.9GB RAM): 100%|██████████| 1094/1094 [00:22<00:00, 48.30it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/BeverageDetection/beverage_detection_training2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/BeverageDetection/beverage_detection_training2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      3.86G      1.208       4.36      1.158        113        640: 100%|██████████| 240/240 [01:11<00:00,  3.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:12<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.495     0.0785     0.0249     0.0182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      3.87G      1.106      2.901      1.133        108        640: 100%|██████████| 240/240 [01:07<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:12<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.487      0.233      0.172      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      3.88G      1.103      2.141      1.138        201        640: 100%|██████████| 240/240 [01:06<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:10<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.538      0.337        0.3      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50       4.6G      1.078      1.819      1.119        121        640: 100%|██████████| 240/240 [01:04<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.575      0.403      0.379      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50       4.6G      1.033      1.576      1.094        125        640: 100%|██████████| 240/240 [01:06<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:09<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.655      0.473      0.461      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50       4.6G     0.9989      1.456      1.079         55        640: 100%|██████████| 240/240 [01:07<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:09<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.669      0.487      0.486      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50       4.6G     0.9708      1.346      1.068         92        640: 100%|██████████| 240/240 [01:04<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:09<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.724      0.531      0.537      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50       4.6G     0.9554      1.309      1.054         22        640: 100%|██████████| 240/240 [01:06<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.686      0.549      0.555      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50       4.6G     0.9502      1.265      1.053         58        640: 100%|██████████| 240/240 [01:05<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.702      0.536      0.559       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50       4.6G     0.9354      1.216      1.042        106        640: 100%|██████████| 240/240 [01:05<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.683      0.573      0.581      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50       4.6G     0.9246      1.168      1.037         93        640: 100%|██████████| 240/240 [01:06<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.749      0.558      0.582      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50       4.6G     0.9043      1.139      1.033         47        640: 100%|██████████| 240/240 [01:06<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:09<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.758      0.565      0.591       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50       4.6G     0.9075      1.121      1.027         58        640: 100%|██████████| 240/240 [01:05<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.714      0.598        0.6      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50       4.6G     0.8972      1.091      1.026         97        640: 100%|██████████| 240/240 [01:05<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.759       0.58      0.614      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50       4.6G     0.8908      1.054       1.02         83        640: 100%|██████████| 240/240 [01:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.696      0.623      0.629      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50       4.6G     0.8788      1.045      1.014         82        640: 100%|██████████| 240/240 [01:06<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.739       0.62      0.643      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      5.16G     0.8706      1.033      1.009         51        640: 100%|██████████| 240/240 [01:06<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.733      0.627      0.642      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      5.16G      0.865     0.9963      1.005         84        640: 100%|██████████| 240/240 [01:07<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535       0.72      0.618       0.64      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      5.16G     0.8551     0.9744      1.002        157        640: 100%|██████████| 240/240 [01:08<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.705      0.661      0.668      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      5.16G     0.8597     0.9608      1.005         66        640: 100%|██████████| 240/240 [01:05<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.696      0.655      0.665      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      5.16G     0.8501     0.9543      1.001         59        640: 100%|██████████| 240/240 [01:06<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.705      0.652      0.667      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      5.16G     0.8452     0.9316     0.9997         75        640: 100%|██████████| 240/240 [01:07<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.735      0.653      0.672      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      5.16G     0.8453     0.9199     0.9973         80        640: 100%|██████████| 240/240 [01:07<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535       0.75      0.662      0.678      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      5.16G     0.8367     0.9026     0.9936        177        640: 100%|██████████| 240/240 [01:05<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.736      0.682      0.693      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      5.16G     0.8328     0.8884     0.9899         87        640: 100%|██████████| 240/240 [01:05<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.714      0.668       0.69      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      5.16G     0.8244     0.8651     0.9855         72        640: 100%|██████████| 240/240 [01:08<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.726      0.697      0.697      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      5.16G     0.8309     0.8614     0.9922         73        640: 100%|██████████| 240/240 [01:06<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.726      0.679      0.697      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      5.72G     0.8255     0.8607     0.9879        147        640: 100%|██████████| 240/240 [01:05<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.696        0.7      0.698      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      5.72G     0.8145     0.8412     0.9825         40        640: 100%|██████████| 240/240 [01:05<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.755      0.684      0.706      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      5.72G     0.8148     0.8448     0.9803        170        640: 100%|██████████| 240/240 [01:07<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.729      0.695      0.699      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      5.72G     0.7971     0.8165     0.9771        171        640: 100%|██████████| 240/240 [01:05<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.744      0.689      0.708       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      5.72G     0.8049     0.8158     0.9752         92        640: 100%|██████████| 240/240 [01:05<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.765      0.682      0.709       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      5.72G     0.7971     0.8031     0.9743        176        640: 100%|██████████| 240/240 [01:06<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:09<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.745      0.702      0.709      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      5.72G     0.7936     0.8004     0.9725        184        640: 100%|██████████| 240/240 [01:05<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.754      0.695      0.706      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      5.72G     0.7906      0.782     0.9748         76        640: 100%|██████████| 240/240 [01:06<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.724      0.708      0.713      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      5.72G     0.7846     0.7735     0.9707         56        640: 100%|██████████| 240/240 [01:05<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.729      0.706      0.715      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      5.72G      0.787     0.7642     0.9668        136        640: 100%|██████████| 240/240 [01:06<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.733      0.696      0.714      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      5.72G     0.7765     0.7598     0.9627         76        640: 100%|██████████| 240/240 [01:05<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:07<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.747      0.702      0.707      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      5.72G     0.7745     0.7537     0.9642        158        640: 100%|██████████| 240/240 [01:05<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.746      0.721       0.72      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      5.72G     0.7691     0.7458      0.965         77        640: 100%|██████████| 240/240 [01:04<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.739      0.718       0.72      0.575\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      5.72G     0.7522      0.706      0.964         57        640: 100%|██████████| 240/240 [01:06<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535       0.74      0.684       0.71      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      5.72G     0.7391     0.6861     0.9617         56        640: 100%|██████████| 240/240 [01:02<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.734      0.712      0.714      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      5.72G      0.738       0.68     0.9591         11        640: 100%|██████████| 240/240 [01:02<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.711      0.716      0.715      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      5.72G     0.7295     0.6648     0.9551         54        640: 100%|██████████| 240/240 [01:04<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535       0.74      0.717      0.716      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      5.72G     0.7228     0.6543     0.9533         62        640: 100%|██████████| 240/240 [01:02<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.762      0.707      0.714      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      5.72G     0.7172     0.6464     0.9526         30        640: 100%|██████████| 240/240 [01:03<00:00,  3.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.755       0.71      0.717      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      5.72G     0.7154     0.6304     0.9497         54        640: 100%|██████████| 240/240 [01:02<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.729      0.717      0.721      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      5.72G     0.7097     0.6277     0.9495         89        640: 100%|██████████| 240/240 [01:03<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.752      0.709      0.718      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      5.72G     0.7058     0.6243     0.9475         47        640: 100%|██████████| 240/240 [01:03<00:00,  3.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.715      0.727       0.72      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      5.72G     0.7068     0.6129     0.9454         48        640: 100%|██████████| 240/240 [01:03<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:08<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.738      0.724      0.721      0.582\n",
            "\n",
            "50 epochs completed in 1.044 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/BeverageDetection/beverage_detection_training2/weights/last.pt, 6.4MB\n",
            "Optimizer stripped from /content/drive/MyDrive/BeverageDetection/beverage_detection_training2/weights/best.pt, 6.4MB\n",
            "\n",
            "Validating /content/drive/MyDrive/BeverageDetection/beverage_detection_training2/weights/best.pt...\n",
            "Ultralytics 8.3.145 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:16<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.738      0.725      0.721      0.582\n",
            "     7-UP-200-ML-GLASS         53        122      0.778      0.738      0.796      0.614\n",
            "      7-UP-2250-ML-PET        163        236      0.901      0.883      0.936      0.795\n",
            "       7-UP-250-ML-PET        364        788      0.923      0.982      0.982      0.774\n",
            "     7-UP-300-ML-GLASS          7         18      0.274     0.0556      0.181       0.12\n",
            "       7-UP-500-ML-PET        207        493      0.932      0.948      0.975      0.808\n",
            "       7-UP-600-ML-PET        117        192      0.515       0.62      0.584      0.485\n",
            "       7-UP-750-ML-PET        136        237      0.621      0.837      0.694      0.613\n",
            "       7-UP-CAN-250-ML         20         37      0.331      0.388      0.345      0.306\n",
            "       7-UP-CAN-300-ML         44        109      0.728      0.927      0.783      0.647\n",
            "      7-UP-PET-1250-ML        186        246      0.889      0.927      0.945      0.824\n",
            "      AQUAFINA-1000-ML        279        965      0.847      0.947      0.931      0.814\n",
            "  AQUAFINA-2000-ML-PET         57        130      0.598      0.523      0.475      0.404\n",
            "   AQUAFINA-500-ML-PET        119        323      0.828      0.836      0.846      0.724\n",
            "             COCA-COLA          6         43       0.86      0.858      0.922      0.737\n",
            "         COCA-COLA-CAN          4         32      0.433      0.625      0.567      0.435\n",
            "EVERESS-SODA-250-ML-PET        117        253      0.904      0.966      0.982        0.8\n",
            "EVERESS-SODA-PET-750-ML        251        468      0.904       0.97      0.968      0.786\n",
            "EVERESS-SODA-RGB-300-ML         17         31      0.873      0.935      0.947      0.691\n",
            "                 FANTA          8         12      0.563       0.25      0.317      0.226\n",
            "                FROOTI          3          4          0          0     0.0388     0.0282\n",
            "  GATORADE-BLUE-250-ML         17         56      0.801      0.875      0.894      0.609\n",
            "  GATORADE-LIME-250-ML          6         10      0.808        0.9      0.887      0.651\n",
            "GATORADE-ORANGE-250-ML         11         20      0.884       0.45      0.505       0.38\n",
            "                 LIMCA          3          5          1          0     0.0325     0.0255\n",
            "   MIR-ORG-PET 2250 ML        142        156      0.849      0.863      0.912      0.797\n",
            "   MIR-ORG-PET-1250-ML        182        238      0.798      0.857      0.917      0.802\n",
            "   MIR-ORG-PET-2250-ML          1          3          1          0          0          0\n",
            "    MIR-ORG-PET-600-ML        147        207      0.563      0.722      0.684      0.563\n",
            "    MIR-ORG-PET-750-ML        155        282      0.637       0.72      0.674      0.574\n",
            "MIRINDA-ORANGE-300-ML-CAN         51         93      0.942      0.968      0.973      0.769\n",
            "MIRINDA-ORANGE-300-ML-GLASS         44         94      0.758      0.872       0.81      0.594\n",
            "MIRINDA-ORANGE-300-ML-PET        184        378      0.849      0.926      0.916      0.719\n",
            "MOUNTAIN-DEW-200-ML-GLASS         79        256      0.757      0.935      0.866      0.668\n",
            "MOUNTAIN-DEW-2250-ML-PET         14         27      0.833      0.778      0.761      0.648\n",
            "MOUNTAIN-DEW-250 ML-PET        366       1094       0.92       0.96      0.971      0.811\n",
            "MOUNTAIN-DEW-250-ML-CAN         24         37      0.344      0.326      0.312      0.254\n",
            "MOUNTAIN-DEW-250ML-PET          1          2          1          0     0.0376     0.0376\n",
            "MOUNTAIN-DEW-300-ML-CAN         36         81       0.73      0.877      0.823      0.716\n",
            "MOUNTAIN-DEW-300-ML-GLASS          7         21          1          0       0.14        0.1\n",
            "MOUNTAIN-DEW-500-ML-PET          6          6          0          0     0.0905     0.0565\n",
            "MOUNTAIN-DEW-600-ML-PET         29         85      0.451      0.588      0.509       0.41\n",
            "           Nimbooz-Pet        148        274      0.952       0.94       0.97      0.811\n",
            "         Nimbooz-Tetra        104        242      0.887      0.926      0.944      0.711\n",
            "      PEPSI-250 ML-PET        341        905      0.882      0.924      0.962      0.807\n",
            "      PEPSI-250-ML-PET         66        190      0.595      0.816      0.699      0.637\n",
            "PEPSI-BLACK-500-ML-PET        229        442      0.924      0.957      0.965      0.735\n",
            "PEPSI-BLACK-CAN-300-ML         47        166      0.885       0.91      0.938      0.719\n",
            "      PEPSI-CAN-250-ML         99        238       0.91      0.971      0.978      0.843\n",
            "PEPSI-COLA-200-ML-GLASS         93        261      0.859      0.962      0.938      0.704\n",
            " PEPSI-COLA-500-ML-PET         17         35      0.902        0.6      0.699      0.604\n",
            " PEPSI-COLA-600-ML-PET         94        241      0.679      0.738      0.786      0.653\n",
            " PEPSI-COLA-750-ML-PET        228        495      0.661      0.885      0.845      0.706\n",
            "     PEPSI-PET-1250-ML        220        375      0.884      0.918      0.943      0.818\n",
            "     PEPSI-PET-2250-ML        133        189      0.827      0.847      0.884      0.741\n",
            "              RED-BULL          4          8      0.212       0.37      0.158      0.108\n",
            "      SLICE-350-ML-PET        198        467      0.875      0.963      0.937      0.768\n",
            "SLICE-MANGO-1200-ML-PET         49         87      0.941      0.917      0.951      0.819\n",
            "SLICE-MANGO-125-ML-TETRA        142        435        0.9      0.947      0.966      0.718\n",
            "SLICE-MANGO-600-ML-PET        195        383      0.955      0.966      0.972      0.821\n",
            "                SPRITE          8         17      0.451      0.353      0.335      0.255\n",
            "    STING-200-ML-GLASS         62        133      0.867      0.955      0.947      0.621\n",
            "      STING-250-ML-CAN         50        115      0.891      0.904      0.935      0.797\n",
            "      STING-250-ML-PET        368       1133       0.93      0.944      0.969      0.713\n",
            " STING-250-ML-PET-BLUE        323        823      0.952      0.972      0.985      0.743\n",
            "      STING-500 ML-PET        160        283      0.789      0.905      0.868      0.663\n",
            "      STING-500-ML-PET         36         64      0.624      0.766      0.796      0.717\n",
            "             THUMBS-UP         11         23      0.194      0.217      0.269      0.209\n",
            "         THUMBS-UP-CAN          2          8      0.318          1      0.436      0.276\n",
            "        Trop-Apple-Pet         75        139      0.874      0.798      0.881      0.714\n",
            "        Trop-Guava-Pet         52        147      0.848      0.947      0.936       0.78\n",
            "    Trop-Mix-Fruit-Pet        113        273      0.872       0.87      0.944      0.764\n",
            "           WATERBOTTLE         11         54       0.19      0.156      0.178      0.143\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/BeverageDetection/beverage_detection_training2\u001b[0m\n",
            "📁 Best model saved to: /content/drive/MyDrive/BeverageDetection/models/best_models/best_beverage_model.pt\n",
            "💾 Training state saved at epoch 50\n",
            "\n",
            "🎉 Training completed successfully!\n",
            "⏰ Completed at: 2025-05-27 18:43:22\n",
            "📈 Final Metrics:\n",
            "   mAP@0.5: 0.7215\n",
            "   mAP@0.5:0.95: 0.5824\n",
            "   Precision: 0.7383\n",
            "   Recall: 0.7246\n",
            "🎉 Training completed successfully!\n",
            "📊 Training plots saved in: /content/drive/MyDrive/BeverageDetection/beverage_detection_training\n",
            "\n",
            "🔍 Quick Model Validation:\n",
            "Ultralytics 8.3.145 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,091,487 parameters, 0 gradients, 8.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 106.9±14.3 MB/s, size: 354.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/BeverageDetection/dataset/valid/labels.cache... 1094 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1094/1094 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/valid/images/2815_jpg.rf.263b9fd7ba997f6278fbc88329ae4bce.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/valid/images/2865_jpg.rf.3020ef0dda8fb2e35f6ac8c4edfd3164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/BeverageDetection/dataset/valid/images/4021_jpg.rf.3516dd531ebfffd96b025e25fd67e363.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.9GB RAM): 100%|██████████| 1094/1094 [00:24<00:00, 44.52it/s] \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 69/69 [00:15<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1094      16535      0.715      0.736      0.721      0.584\n",
            "     7-UP-200-ML-GLASS         53        122      0.745       0.74      0.797      0.619\n",
            "      7-UP-2250-ML-PET        163        236      0.902      0.893      0.935      0.796\n",
            "       7-UP-250-ML-PET        364        788      0.916      0.982      0.982      0.775\n",
            "     7-UP-300-ML-GLASS          7         18      0.264     0.0823      0.179      0.119\n",
            "       7-UP-500-ML-PET        207        493      0.925      0.951      0.975       0.81\n",
            "       7-UP-600-ML-PET        117        192      0.519      0.651      0.583      0.486\n",
            "       7-UP-750-ML-PET        136        237      0.614      0.865      0.698      0.619\n",
            "       7-UP-CAN-250-ML         20         37      0.327      0.486      0.342      0.309\n",
            "       7-UP-CAN-300-ML         44        109      0.725      0.941      0.786      0.648\n",
            "      7-UP-PET-1250-ML        186        246       0.89      0.927      0.946      0.827\n",
            "      AQUAFINA-1000-ML        279        965       0.84      0.947      0.931      0.815\n",
            "  AQUAFINA-2000-ML-PET         57        130      0.584      0.523      0.475      0.402\n",
            "   AQUAFINA-500-ML-PET        119        323      0.823      0.837      0.846      0.724\n",
            "             COCA-COLA          6         43      0.854       0.86      0.924      0.735\n",
            "         COCA-COLA-CAN          4         32      0.429      0.625      0.567      0.443\n",
            "EVERESS-SODA-250-ML-PET        117        253      0.897      0.968      0.982      0.804\n",
            "EVERESS-SODA-PET-750-ML        251        468      0.897       0.97      0.968      0.786\n",
            "EVERESS-SODA-RGB-300-ML         17         31      0.869      0.935      0.947      0.702\n",
            "                 FANTA          8         12      0.408       0.25      0.317      0.226\n",
            "                FROOTI          3          4          0          0     0.0388     0.0282\n",
            "  GATORADE-BLUE-250-ML         17         56      0.775      0.875      0.894       0.61\n",
            "  GATORADE-LIME-250-ML          6         10      0.801        0.9      0.887      0.651\n",
            "GATORADE-ORANGE-250-ML         11         20      0.874       0.45      0.507      0.385\n",
            "                 LIMCA          3          5          1          0     0.0325     0.0255\n",
            "   MIR-ORG-PET 2250 ML        142        156      0.846      0.877      0.911      0.803\n",
            "   MIR-ORG-PET-1250-ML        182        238      0.784      0.866      0.917      0.803\n",
            "   MIR-ORG-PET-2250-ML          1          3          1          0          0          0\n",
            "    MIR-ORG-PET-600-ML        147        207      0.554      0.749      0.682      0.561\n",
            "    MIR-ORG-PET-750-ML        155        282       0.63      0.745      0.673      0.575\n",
            "MIRINDA-ORANGE-300-ML-CAN         51         93      0.923      0.968      0.973      0.775\n",
            "MIRINDA-ORANGE-300-ML-GLASS         44         94      0.756      0.891       0.81      0.595\n",
            "MIRINDA-ORANGE-300-ML-PET        184        378      0.834       0.93      0.916      0.721\n",
            "MOUNTAIN-DEW-200-ML-GLASS         79        256       0.75      0.938      0.865      0.671\n",
            "MOUNTAIN-DEW-2250-ML-PET         14         27      0.782      0.798      0.757      0.643\n",
            "MOUNTAIN-DEW-250 ML-PET        366       1094      0.915      0.963      0.971      0.812\n",
            "MOUNTAIN-DEW-250-ML-CAN         24         37      0.393      0.432       0.31      0.253\n",
            "MOUNTAIN-DEW-250ML-PET          1          2          1          0     0.0376     0.0376\n",
            "MOUNTAIN-DEW-300-ML-CAN         36         81      0.715      0.877      0.821      0.716\n",
            "MOUNTAIN-DEW-300-ML-GLASS          7         21          0          0      0.138     0.0979\n",
            "MOUNTAIN-DEW-500-ML-PET          6          6      0.117      0.167     0.0905     0.0565\n",
            "MOUNTAIN-DEW-600-ML-PET         29         85      0.444       0.62      0.504      0.404\n",
            "           Nimbooz-Pet        148        274      0.948      0.945       0.97      0.814\n",
            "         Nimbooz-Tetra        104        242      0.872      0.927      0.944      0.714\n",
            "      PEPSI-250 ML-PET        341        905      0.874      0.931      0.962      0.808\n",
            "      PEPSI-250-ML-PET         66        190      0.585      0.826      0.698      0.636\n",
            "PEPSI-BLACK-500-ML-PET        229        442      0.922      0.961      0.965      0.735\n",
            "PEPSI-BLACK-CAN-300-ML         47        166      0.853       0.91      0.938      0.718\n",
            "      PEPSI-CAN-250-ML         99        238      0.906      0.971      0.978      0.844\n",
            "PEPSI-COLA-200-ML-GLASS         93        261      0.848      0.965      0.938      0.704\n",
            " PEPSI-COLA-500-ML-PET         17         35      0.877        0.6      0.701      0.608\n",
            " PEPSI-COLA-600-ML-PET         94        241      0.665      0.763      0.784      0.651\n",
            " PEPSI-COLA-750-ML-PET        228        495      0.653      0.889      0.845      0.706\n",
            "     PEPSI-PET-1250-ML        220        375      0.881      0.927      0.943      0.819\n",
            "     PEPSI-PET-2250-ML        133        189      0.802      0.852      0.885      0.747\n",
            "              RED-BULL          4          8      0.181      0.375      0.159      0.112\n",
            "      SLICE-350-ML-PET        198        467      0.873      0.966      0.937      0.767\n",
            "SLICE-MANGO-1200-ML-PET         49         87      0.941      0.919      0.951      0.823\n",
            "SLICE-MANGO-125-ML-TETRA        142        435      0.885      0.954      0.965      0.717\n",
            "SLICE-MANGO-600-ML-PET        195        383      0.951      0.969      0.972      0.821\n",
            "                SPRITE          8         17      0.411      0.353      0.338      0.256\n",
            "    STING-200-ML-GLASS         62        133      0.865      0.955      0.946       0.62\n",
            "      STING-250-ML-CAN         50        115      0.869      0.904      0.934      0.797\n",
            "      STING-250-ML-PET        368       1133      0.922      0.946      0.972      0.713\n",
            " STING-250-ML-PET-BLUE        323        823      0.948      0.974      0.985      0.745\n",
            "      STING-500 ML-PET        160        283      0.776      0.905      0.869      0.663\n",
            "      STING-500-ML-PET         36         64      0.595      0.766      0.796      0.712\n",
            "             THUMBS-UP         11         23      0.178      0.225      0.274      0.214\n",
            "         THUMBS-UP-CAN          2          8      0.294          1      0.436      0.274\n",
            "        Trop-Apple-Pet         75        139      0.869      0.806      0.881      0.714\n",
            "        Trop-Guava-Pet         52        147      0.844      0.966      0.936      0.783\n",
            "    Trop-Mix-Fruit-Pet        113        273      0.858      0.886      0.944      0.767\n",
            "           WATERBOTTLE         11         54        0.2      0.177      0.178      0.142\n",
            "Speed: 0.3ms preprocess, 3.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/BeverageDetection/beverage_detection_training22\u001b[0m\n",
            "   Validation mAP@0.5: 0.7215\n",
            "   Validation mAP@0.5:0.95: 0.5835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lakXZjqcOF5E",
        "outputId": "c96bb2e6-7ad0-4fa7-e74b-5de3017dd05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive Model Evaluation\n",
        "import json\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/BeverageDetection/models/best_models/best_beverage_model.pt\"\n",
        "DATASET_YAML = \"/content/drive/MyDrive/BeverageDetection/dataset/data.yaml\"\n",
        "\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    model = YOLO(MODEL_PATH)\n",
        "\n",
        "    print(\"📊 COMPREHENSIVE MODEL EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. Overall Validation Metrics\n",
        "    print(\"\\n1️⃣ OVERALL PERFORMANCE\")\n",
        "    val_results = model.val(data=DATASET_YAML)\n",
        "\n",
        "    print(f\"📈 Key Metrics:\")\n",
        "    print(f\"   • mAP@0.5 (IoU=0.5): {val_results.box.map50:.4f}\")\n",
        "    print(f\"   • mAP@0.5:0.95 (IoU=0.5-0.95): {val_results.box.map:.4f}\")\n",
        "    print(f\"   • Precision: {val_results.box.mp:.4f}\")\n",
        "    print(f\"   • Recall: {val_results.box.mr:.4f}\")\n",
        "    print(f\"   • F1-Score: {2 * (val_results.box.mp * val_results.box.mr) / (val_results.box.mp + val_results.box.mr):.4f}\")\n",
        "\n",
        "    # 2. Per-Class Performance\n",
        "    print(f\"\\n2️⃣ PER-CLASS PERFORMANCE\")\n",
        "    if hasattr(val_results.box, 'ap_class_index') and len(val_results.box.ap_class_index) > 0:\n",
        "        class_names = model.names\n",
        "        for i, class_idx in enumerate(val_results.box.ap_class_index):\n",
        "            class_name = class_names[class_idx]\n",
        "            ap50 = val_results.box.ap50[i] if i < len(val_results.box.ap50) else 0\n",
        "            ap = val_results.box.ap[i] if i < len(val_results.box.ap) else 0\n",
        "            print(f\"   📱 {class_name}:\")\n",
        "            print(f\"      • AP@0.5: {ap50:.4f}\")\n",
        "            print(f\"      • AP@0.5:0.95: {ap:.4f}\")\n",
        "\n",
        "    # 3. Model Information\n",
        "    print(f\"\\n3️⃣ MODEL INFORMATION\")\n",
        "    print(f\"   • Model Type: YOLOv8\")\n",
        "    print(f\"   • Classes: {len(model.names)}\")\n",
        "    print(f\"   • Class Names: {list(model.names.values())}\")\n",
        "    print(f\"   • Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
        "\n",
        "    # 4. Speed Benchmarks\n",
        "    print(f\"\\n4️⃣ SPEED BENCHMARK\")\n",
        "    print(\"⏱️  Running speed test...\")\n",
        "    speed_results = model.val(data=DATASET_YAML, verbose=False)\n",
        "    if hasattr(speed_results, 'speed'):\n",
        "        print(f\"   • Preprocess: {speed_results.speed['preprocess']:.2f}ms\")\n",
        "        print(f\"   • Inference: {speed_results.speed['inference']:.2f}ms\")\n",
        "        print(f\"   • Postprocess: {speed_results.speed['postprocess']:.2f}ms\")\n",
        "        total_time = sum(speed_results.speed.values())\n",
        "        print(f\"   • Total per image: {total_time:.2f}ms\")\n",
        "        print(f\"   • FPS: {1000/total_time:.1f}\")\n",
        "\n",
        "    # 5. Training History (if available)\n",
        "    print(f\"\\n5️⃣ TRAINING HISTORY\")\n",
        "    training_log_path = \"/content/drive/MyDrive/BeverageDetection/training_log.json\"\n",
        "    if os.path.exists(training_log_path):\n",
        "        with open(training_log_path, 'r') as f:\n",
        "            training_data = json.load(f)\n",
        "            print(f\"   • Training completed: {training_data.get('timestamp', 'Unknown')}\")\n",
        "            print(f\"   • Final epoch: {training_data.get('epoch', 'Unknown')}\")\n",
        "            if 'metrics' in training_data:\n",
        "                metrics = training_data['metrics']\n",
        "                print(f\"   • Final mAP@0.5: {metrics.get('map50', 'N/A')}\")\n",
        "                print(f\"   • Final mAP@0.5:0.95: {metrics.get('map', 'N/A')}\")\n",
        "\n",
        "    # 6. Performance Interpretation\n",
        "    print(f\"\\n6️⃣ PERFORMANCE INTERPRETATION\")\n",
        "    map50 = val_results.box.map50\n",
        "    if map50 >= 0.8:\n",
        "        performance = \"🟢 EXCELLENT\"\n",
        "    elif map50 >= 0.6:\n",
        "        performance = \"🟡 GOOD\"\n",
        "    elif map50 >= 0.4:\n",
        "        performance = \"🟠 FAIR\"\n",
        "    else:\n",
        "        performance = \"🔴 NEEDS IMPROVEMENT\"\n",
        "\n",
        "    print(f\"   Overall Performance: {performance}\")\n",
        "    print(f\"   mAP@0.5 of {map50:.3f} means:\")\n",
        "    print(f\"   • The model correctly detects objects {map50*100:.1f}% of the time\")\n",
        "    print(f\"   • At IoU threshold of 0.5 (50% overlap required)\")\n",
        "\n",
        "    # 7. Recommendations\n",
        "    print(f\"\\n7️⃣ RECOMMENDATIONS\")\n",
        "    if map50 < 0.5:\n",
        "        print(\"   🔧 Model needs improvement:\")\n",
        "        print(\"      • Increase training epochs\")\n",
        "        print(\"      • Add more training data\")\n",
        "        print(\"      • Check data quality and annotations\")\n",
        "        print(\"      • Try different augmentations\")\n",
        "    elif map50 < 0.7:\n",
        "        print(\"   ⚡ Model is decent but can be improved:\")\n",
        "        print(\"      • Fine-tune hyperparameters\")\n",
        "        print(\"      • Add more diverse training data\")\n",
        "        print(\"      • Consider ensemble methods\")\n",
        "    else:\n",
        "        print(\"   ✅ Model performance is good!\")\n",
        "        print(\"      • Ready for deployment\")\n",
        "        print(\"      • Consider speed optimizations if needed\")\n",
        "        print(\"      • Test on real-world scenarios\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Model not found: {MODEL_PATH}\")\n",
        "    print(\"Please ensure training completed successfully\")"
      ],
      "metadata": {
        "id": "CIOoKRfezBs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bdw6gx-2LqoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "\n",
        "class BeverageDetectionTrainer:\n",
        "    def __init__(self, dataset_yaml_path, project_root):\n",
        "        self.dataset_yaml_path = dataset_yaml_path\n",
        "        self.project_root = project_root\n",
        "        self.checkpoints_path = os.path.join(project_root, \"models/checkpoints\")\n",
        "        self.best_models_path = os.path.join(project_root, \"models/best_models\")\n",
        "        self.training_log_path = os.path.join(project_root, \"training_log.json\")\n",
        "\n",
        "        os.makedirs(self.checkpoints_path, exist_ok=True)\n",
        "        os.makedirs(self.best_models_path, exist_ok=True)\n",
        "\n",
        "    def save_training_state(self, epoch, model_path, metrics):\n",
        "        state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_path\": model_path,\n",
        "            \"metrics\": metrics,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"dataset_path\": self.dataset_yaml_path\n",
        "        }\n",
        "        with open(self.training_log_path, \"w\") as f:\n",
        "            json.dump(state, f, indent=2)\n",
        "        print(f\"💾 Saved training state at epoch {epoch}\")\n",
        "\n",
        "    def load_training_state(self):\n",
        "        if os.path.exists(self.training_log_path):\n",
        "            with open(self.training_log_path, \"r\") as f:\n",
        "                state = json.load(f)\n",
        "            print(f\"📂 Loaded previous training state from epoch {state['epoch']}\")\n",
        "            return state\n",
        "        return None\n",
        "\n",
        "    def train_model(self, epochs=150, img_size=416, batch_size=8, resume=True):\n",
        "        if not os.path.exists(self.dataset_yaml_path):\n",
        "            raise FileNotFoundError(f\"❌ Dataset YAML not found: {self.dataset_yaml_path}\")\n",
        "\n",
        "        previous_state = self.load_training_state() if resume else None\n",
        "\n",
        "        if previous_state and os.path.exists(previous_state[\"model_path\"]):\n",
        "            print(f\"🔄 Resuming training from {previous_state['model_path']}\")\n",
        "            model = YOLO(previous_state[\"model_path\"])\n",
        "            start_epoch = previous_state[\"epoch\"]\n",
        "        else:\n",
        "            print(\"🚀 Starting fresh training with base model (yolov8n.pt)\")\n",
        "            model = YOLO(\"yolov8n.pt\")\n",
        "            start_epoch = 0\n",
        "\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"🖥️  Training on: {device}\")\n",
        "\n",
        "        train_params = {\n",
        "            \"data\": self.dataset_yaml_path,\n",
        "            \"epochs\": epochs,\n",
        "            \"imgsz\": img_size,\n",
        "            \"batch\": batch_size,\n",
        "            \"device\": device,\n",
        "            \"workers\": 4 if device == \"cuda\" else 2,\n",
        "            \"project\": self.project_root,\n",
        "            \"name\": \"beverage_detection_training\",\n",
        "            \"save_period\": 10,\n",
        "            \"patience\": 50,\n",
        "            \"save\": True,\n",
        "            \"val\": True,\n",
        "            \"plots\": False,\n",
        "            \"verbose\": False,\n",
        "            \"cache\": \"ram\",\n",
        "            \"optimizer\": \"SGD\",\n",
        "            \"lr0\": 0.01,\n",
        "            \"momentum\": 0.937,\n",
        "            \"weight_decay\": 0.0005,\n",
        "            \"warmup_epochs\": 3.0,\n",
        "            \"warmup_momentum\": 0.8,\n",
        "            \"warmup_bias_lr\": 0.1\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\n⏰ Training started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            results = model.train(**train_params)\n",
        "\n",
        "            best_model_src = results.save_dir / \"weights\" / \"best.pt\"\n",
        "            best_model_dst = os.path.join(self.best_models_path, \"best_beverage_model.pt\")\n",
        "            if os.path.exists(best_model_src):\n",
        "                shutil.copy(str(best_model_src), best_model_dst)\n",
        "                print(f\"📁 Best model saved to: {best_model_dst}\")\n",
        "\n",
        "            # Extract metrics if available\n",
        "            final_metrics = {}\n",
        "            try:\n",
        "                if hasattr(results, \"box\"):\n",
        "                    final_metrics = {\n",
        "                        \"map50\": float(results.box.map50),\n",
        "                        \"map\": float(results.box.map),\n",
        "                        \"precision\": float(results.box.mp),\n",
        "                        \"recall\": float(results.box.mr)\n",
        "                    }\n",
        "            except Exception as metric_err:\n",
        "                print(f\"⚠️ Metric extraction failed: {metric_err}\")\n",
        "                final_metrics = {\"error\": str(metric_err)}\n",
        "\n",
        "            self.save_training_state(epochs, best_model_dst, final_metrics)\n",
        "\n",
        "            print(\"\\n🎉 Training complete!\")\n",
        "            print(\"📊 Final Evaluation:\")\n",
        "            for k, v in final_metrics.items():\n",
        "                print(f\"   {k.upper()}: {v:.4f}\" if isinstance(v, float) else f\"   {k}: {v}\")\n",
        "\n",
        "            return model, results\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n⏸️  Training interrupted by user.\")\n",
        "            self._save_interrupted_state(model, start_epoch)\n",
        "            raise\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Unexpected error: {e}\")\n",
        "            self._save_interrupted_state(model, start_epoch)\n",
        "            raise\n",
        "\n",
        "    def _save_interrupted_state(self, model, start_epoch):\n",
        "        try:\n",
        "            epoch = getattr(model.trainer, \"epoch\", start_epoch)\n",
        "            checkpoint_path = os.path.join(self.checkpoints_path, f\"interrupted_epoch_{epoch}.pt\")\n",
        "            if hasattr(model.trainer, \"last\") and os.path.exists(model.trainer.last):\n",
        "                shutil.copy(model.trainer.last, checkpoint_path)\n",
        "                self.save_training_state(epoch, checkpoint_path, {})\n",
        "                print(f\"💾 Checkpoint saved at epoch {epoch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to save interrupted state: {e}\")\n",
        "\n",
        "    def validate_model(self, model_path=None):\n",
        "        model_path = model_path or os.path.join(self.best_models_path, \"best_beverage_model.pt\")\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"❌ Model file not found: {model_path}\")\n",
        "            return None\n",
        "\n",
        "        print(f\"🔍 Validating model at: {model_path}\")\n",
        "        model = YOLO(model_path)\n",
        "        results = model.val(data=self.dataset_yaml_path)\n",
        "\n",
        "        print(\"\\n📈 Validation Metrics:\")\n",
        "        print(f\"   mAP@0.5:     {results.box.map50:.4f}\")\n",
        "        print(f\"   mAP@0.5:0.95:{results.box.map:.4f}\")\n",
        "        print(f\"   Precision:   {results.box.mp:.4f}\")\n",
        "        print(f\"   Recall:      {results.box.mr:.4f}\")\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "Lt8fUI9zvPoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}